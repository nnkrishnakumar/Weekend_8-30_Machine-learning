{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08052c1f-a550-4f62-a404-1c3d5def3449",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3451148652.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Ducat\\AppData\\Local\\Temp\\ipykernel_4348\\3451148652.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    NLP:(Natural Language Processing)\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "NLP:(Natural Language Processing)\n",
    "\n",
    "> nltk  --> long process to work with NLP\n",
    "\n",
    "> sklearn  --> little short then nltk\n",
    "\n",
    "> textblob  --> it is most fast library to work on NLP.\n",
    "    \n",
    "\n",
    "reviews of a restra \n",
    "\n",
    "review of book\n",
    "\n",
    "gmail spam,ham\n",
    "\n",
    "comparing two books/ movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7921b4f-a947-4a9c-a507-50d12396ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58cb1c4d-0290-4c98-803b-ae4d44b6e54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ad93a78-c022-4432-b99e-2ff7bafcecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1='foo324d is GoOd!'\n",
    "doc2='Food is not Tasty.'\n",
    "doc3='It is too Costly'\n",
    "doc4='Wow food is awesome food'\n",
    "doc5='worst tas32@$5te!!'\n",
    "\n",
    "target=['pos','neg','neg','pos','neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ed46650-1486-4896-8a45-1e1739728d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[doc1,doc2,doc3,doc4,doc5]   # collection of document is called corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b1a4bf8-11c0-4ea2-afbf-dd8964778c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo324d is GoOd!',\n",
       " 'Food is not Tasty.',\n",
       " 'It is too Costly',\n",
       " 'Wow food is awesome food',\n",
       " 'worst tas32@$5te!!']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b367b74e-28da-4d87-9f5f-32ac9fae3455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd24dce0-04a0-4aff-b2ac-0886218031eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo324d is good!',\n",
       " 'food is not tasty.',\n",
       " 'it is too costly',\n",
       " 'wow food is awesome food',\n",
       " 'worst tas32@$5te!!']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus1=list(map(str.lower,corpus))\n",
    "corpus1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec5c25c-5da7-4327-b710-01253aa17710",
   "metadata": {},
   "source": [
    "# step2: \n",
    "\n",
    "removing all the punctuation marks !@#$%^&*()_ and number from corpus\n",
    "\n",
    "Step2: method 1st:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24a02847-35e4-4e36-b471-cffb0d3fe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32c2687a-3be8-4ddb-bce2-1d02a2c4ec3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0be0affc-1de8-4d85-92c0-f3c6f2ee10e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'food is not good'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"[^a-z ]\",\"\",\"food is not g32432ood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b381d5f-3b9d-4fbf-8acc-132afa8921ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(arg):\n",
    "    corpus3=[]\n",
    "    for i in arg:\n",
    "        corpus3.append(re.sub(\"[^a-z ]\",\"\",i))\n",
    "    return corpus3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2316338-ba9b-4006-8df5-85501a19a25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food is good',\n",
       " 'food is not tasty',\n",
       " 'it is too costly',\n",
       " 'wow food is awesome food',\n",
       " 'worst taste']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus3=remove(corpus1)\n",
    "corpus3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02154426-5177-48e8-81db-8677bb6e124e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo324d is GoOd!',\n",
       " 'Food is not Tasty.',\n",
       " 'It is too Costly',\n",
       " 'Wow food is awesome food',\n",
       " 'worst tas32@$5te!!']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53f4712f-ac19-4f55-896c-9d068b71f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bab646a-8d06-426e-8b63-53cca5291ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw=stopwords.words(\"english\")\n",
    "len(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a7e05c4-2b86-4701-9875-a6bde7b6a2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw.remove('not')\n",
    "len(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73cc89bb-56dd-43f3-991b-c5ecb7e64361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw.remove(\"no\")\n",
    "len(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "796bf7ee-e531-4302-9614-63748372828e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food is good',\n",
       " 'food is not tasty',\n",
       " 'it is too costly',\n",
       " 'wow food is awesome food',\n",
       " 'worst taste']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "830d067c-c0c8-4399-8c36-c5f540d72025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_remover(arg):\n",
    "    corpus4=[]\n",
    "    for i in arg:\n",
    "        token=i.split()\n",
    "        st=\"\"\n",
    "        for j in token:\n",
    "            if j in sw:\n",
    "                pass\n",
    "            else:\n",
    "                st+=j+\" \"\n",
    "        corpus4.append(st.strip())\n",
    "    return corpus4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7580f1c9-0ce6-4998-8db6-b433f89c66cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food', 'is', 'good']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus3[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffc89838-f81b-46f4-b7a3-5f65aca3e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e54edb5-0c7f-4971-803d-840bd9f174e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food', 'is', 'good']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd520c3e-9987-4624-8ceb-1dbc1581bfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food good',\n",
       " 'food not tasty',\n",
       " 'costly',\n",
       " 'wow food awesome food',\n",
       " 'worst taste']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus5=stopword_remover(corpus3)\n",
    "corpus5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f09ecdc-d363-4b51-8342-930a2d7ebe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79aeb6d5-8800-4173-afa2-a2bdf2efa149",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf3682a8-0112-40ca-98df-ed49b5408db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp=cv.fit_transform(corpus5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ecbb533d-95d7-4b90-8468-462654b55e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ducat\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['awesome', 'costly', 'food', 'good', 'not', 'taste', 'tasty', 'worst', 'wow']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5343281a-f75e-491d-93d1-1c10cabbbad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 6)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 2)\t2\n",
      "  (3, 8)\t1\n",
      "  (3, 0)\t1\n",
      "  (4, 7)\t1\n",
      "  (4, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "print(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc136e05-d0d5-474f-90b4-dc7c71fcbadd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4348\\2549378993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdense_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# dense matrix is also called feature in NLP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "dense_matrix=sp.toarray()    # dense matrix is also called feature in NLP\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e1626-d5df-407d-83f0-dedb67ebadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39128411-a2d9-4dd8-8336-457ec00d5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d9b20ce-5401-43da-a700-c02c149be739",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4348\\4016806455.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression(max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c017661-ebff-468a-8d3f-2a11e440b222",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4348\\3536813657.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdense_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(dense_matrix,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe997ebe-ed25-4b52-b2e1-ee681d412ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=[\"food is costl4534465@#$y\"]\n",
    "def cleaner(arg):\n",
    "    corpus1=list(map(str.lower,arg))     # use this line to convert corpus into smaller case\n",
    "    corpus2=remove(corpus1)              #remove punctuation and number from corpus\n",
    "    corpus3=stopword_remover(corpus2)    # remove stopword like \"is\",\"am\",etc... from corpus\n",
    "    feature_=cv.transform(corpus3).toarray()  #convert copurs into vector 2D array from sparse matrix to dense matrix\n",
    "    return feature_                     # here we get dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "530716a2-9b30-49ec-8e99-cef0b6362a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sample1=cleaner(sample)\n",
    "print(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f400249-07fe-449a-9af3-319b1a781bb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4348\\1259582756.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.predict(sample1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f071fd-b8ed-4a77-81f4-e8757de9c55c",
   "metadata": {},
   "source": [
    "# TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cbe2f988-2771-4b9e-8b11-1a25e5d67d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food good',\n",
       " 'food not tasty',\n",
       " 'costly',\n",
       " 'wow food awesome food',\n",
       " 'worst taste']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03b11b0e-5c92-4266-a3e4-6c6e0a18d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3867f174-c24d-420e-a031-48c559f9912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=TfidfVectorizer(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7fbcee06-3950-419e-bbcc-a8edb6073eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awesome', 'awesome food', 'costly', 'food', 'food awesome', 'food awesome food', 'food good', 'food not', 'food not tasty', 'good', 'not', 'not tasty', 'taste', 'tasty', 'worst', 'worst taste', 'wow', 'wow food', 'wow food awesome']\n"
     ]
    }
   ],
   "source": [
    "sparse_matrix=tf.fit_transform(corpus5)\n",
    "dense_matrix=sparse_matrix.toarray()\n",
    "dense_matrix\n",
    "print(tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb8f9e76-3a3d-4477-90c7-80569b237f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food good',\n",
       " 'food not tasty',\n",
       " 'costly',\n",
       " 'wow food awesome food',\n",
       " 'worst taste']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e536033d-d131-4361-a485-832eaa413ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "166a2348-c4d7-4f84-961d-cb853e535b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f79947e-06dd-4a63-89e3-0cbabd82348e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(dense_matrix,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bc4a3cf2-4593-4353-8529-c11b2143e052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.83088075 0.55645052 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "sample=[\"food is costl4534465@#$y\"]\n",
    "def cleaner(arg):\n",
    "    corpus1=list(map(str.lower,arg))     # use this line to convert corpus into smaller case\n",
    "    corpus2=remove(corpus1)              #remove punctuation and number from corpus\n",
    "    corpus3=stopword_remover(corpus2)    # remove stopword like \"is\",\"am\",etc... from corpus\n",
    "    feature_=tf.transform(corpus3).toarray()  #convert copurs into vector 2D array from sparse matrix to dense matrix\n",
    "    return feature_                     # here we get dense matrix\n",
    "sample2=cleaner(sample)\n",
    "print(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f03c22ee-7987-4e2f-b77d-e10579e54242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos'], dtype='<U3')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d7cbf4b4-b94b-47cc-a77d-8a9ee8e0d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96e89608-6dc3-4c77-a975-d393bbb70455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\Ducat\\Desktop\\AI_batch\\we_830_ML\\NLP\\Restaurant_Reviews.txt\",delimiter=\"\\t\", on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2bd6a554-122f-4b7e-9d63-66d7f2851a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_restra=list(df.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54d44d2a-203c-4fe3-b1ca-e9e9d8ee4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(arg):\n",
    "    corpus1=list(map(str.lower,arg))     # use this line to convert corpus into smaller case\n",
    "    corpus2=remove(corpus1)              #remove punctuation and number from corpus\n",
    "    corpus3=stopword_remover(corpus2)    # remove stopword like \"is\",\"am\",etc... from corpus\n",
    "    return corpus3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13104192-5edd-4add-baff-499a02adfcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "clearned_feature=cleaner(corpus_restra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da2d998-a639-482d-8031-76ba3dbf4f7b",
   "metadata": {},
   "source": [
    "# convert clearned_feature into feature using Tfidvectorizer or countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2cffff4d-ae3a-4ba4-8ac2-1ad6ae40aa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive FeedBack\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "tf=TfidfVectorizer()\n",
    "X=tf.fit_transform(clearned_feature).toarray()\n",
    "y=np.array(df.iloc[:,-1])\n",
    "model3=LogisticRegression(max_iter=2000)\n",
    "model3.fit(X,y)\n",
    "sample3=[\"foo$#@#d is not good and tasty\"]\n",
    "sample3=cleaner(sample3)\n",
    "sample3=tf.transform(sample3).toarray()\n",
    "len(sample3[0])\n",
    "result=model3.predict(sample3)\n",
    "if result[0]==1:\n",
    "    print(\"Positive FeedBack\")\n",
    "else:\n",
    "    print(\"Negative FeedBack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7d06e841-0a43-4ceb-b6bb-d7f400c42a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative FeedBack\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(ngram_range=(1,2))\n",
    "X=tf.fit_transform(clearned_feature).toarray()\n",
    "y=np.array(df.iloc[:,-1])\n",
    "model3=LogisticRegression(max_iter=2000)\n",
    "model3.fit(X,y)\n",
    "sample3=[\"foo$#@#d is not good and tasty\"]\n",
    "sample3=cleaner(sample3)\n",
    "sample3=tf.transform(sample3).toarray()\n",
    "len(sample3[0])\n",
    "result=model3.predict(sample3)\n",
    "if result[0]==1:\n",
    "    print(\"Positive FeedBack\")\n",
    "else:\n",
    "    print(\"Negative FeedBack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf990d72-7867-4083-acad-1c3aadf51ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Using cached textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\ducat\\anaconda\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\ducat\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\ducat\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ducat\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ducat\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\ducat\\anaconda\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.5)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54496bf-459a-4cf5-85dc-0f72dda3f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208f19da-daf5-4b92-9c82-810856735548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elephant\n"
     ]
    }
   ],
   "source": [
    "blob=TextBlob(\"elephanet\")\n",
    "print(blob.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f86352-8a9a-47d7-a676-3d4095cd97f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I had to go to school\n"
     ]
    }
   ],
   "source": [
    "blob=TextBlob(\"I hav to go to schol\".)\n",
    "print(blob.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4140e56e-fa74-4de0-b7bc-2df0200d75d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10140\\1280207325.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mblob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"physics is a subject.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"hi\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\textblob\\blob.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, from_lang, to)\u001b[0m\n\u001b[0;32m    566\u001b[0m             \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m         )\n\u001b[1;32m--> 568\u001b[1;33m         return self.__class__(self.translator.translate(self.raw,\n\u001b[0m\u001b[0;32m    569\u001b[0m                               from_lang=from_lang, to_lang=to))\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\textblob\\translate.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, source, from_lang, to_lang, host, type_)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_translation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\textblob\\translate.py\u001b[0m in \u001b[0;36m_validate_translation\u001b[1;34m(self, source, result)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotTranslated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Translation API returned the input string unchanged.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "blob=TextBlob(\"physics is a subject.\")\n",
    "blob.translate(to=\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadda34-94f7-4abd-a79f-ab13967ae5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
